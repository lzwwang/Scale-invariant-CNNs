# Scale Steerable Filters for Locally-Scale Invariant Convolutional Neural Networks Implementation based on PyTorch


## Code Sturcture
- `scale_steering_lite.py`: Return a Scale-steerable basis filter for a specific pair of filter order $k$ and filter orientation $\phi_j$ :
$$ S^{kj}(r,\phi)=\frac{1}{r^m}(K(\phi,\phi_j)+K(\phi,\phi_j+\pi))e^{i(k(\text{log }r)+\beta)}$$
- `Make_datasets_Scale.py`: Generate scale dataset from the original one, for example, from MNIST to scale-MNIST.
- `ScaleSteerableInvariant_Network.py`:
    - `class steerable_conv`: return the linear combination of the proposed filter basis for different scale
    - `class ScaleConv_steering:` the scale-invariant layer inherit from `nn.Module` including the init function and forward function
    - `class Net_steerinvariant_mnistlocal_scale`: The network used for evaluation including 3 convolutional layers and 2 fully connected layers.
## Evaluation on MINIST-Scale
We have changed the code a little to make it consistent with the updated libraries. The updated version is on our [github](https://github.com/wsgdrfz/SIE-CNN/tree/master/2-SS-CNN).

### MINIST-Scale Generation

The MNIST-Scale is generated by scaling the original MNIST dataset with a random scale factor $s \in (0.3,1)$. 


### SS-CNN
In this paper, SS-CNN is trained, validated, and tested on 10k, 2k, and 50k images from MNIST-Scale respectively. They evaluate it over 6 splits and report the mean and standard deviations of the test errors.

#### Network Architecture
The details of the network architecture are shown below:
```
Scale-invariant layer with scale-steered filters layer 1
max pooling layer 1: 2x2
batch normalization
Scale-invariant layer with scale-steered filters layer 2
max pooling layer 2: 2x2
batch normalization
Scale-invariant layer with scale-steered filters layer 3
max pooling layer 3: 8x8
batch normalization
fully connected layer 1
batch normalization
relu
dropout
fully connected layer 2
```
Each of the convolution layers in the network uses the structure in the figure. The scale-steered kernels are the linear combination of the scale-steerable basis. Then they scale the scale-steered kernels to different sizes to convolve with the input and output the max-pooling responses over scales.
![Scale-invariant layer](https://tva1.sinaimg.cn/large/006tNbRwgy1g9hu0pzy5rj30zu0hc0wo.jpg)

#### Parameters
For the scale-steerable basis filters, they keep the parameters as following:
$\beta=0, k=(0.5,1,2),\phi_j=j(\pi/8),j\in[1,8],\sigma_\phi=\pi/16$.
In this way, each scale-steerable basis filter has $3(\text{range of }k)\times 8(\text{range of }j)\times 2(\text{real and imaginary components})=48$ trainable parameters.

In the SS-CNN layer, each scale-steered kernel is a linear combination of the scale-steerable basis, and the kernel size ranges from $(7,7)$ to $(17,17)$ with only odd size chosen.


### Standard CNN

 For a fair comparison, the standard CNN also has a total of 3 convolutional layers and 2 fully connected layers. The number of trainable parameters for both networks were kept approximately the same.

#### Network Architecture

The details of the network architecture are shown below:

```
convolution layer 1
max pooling layer 1: 2x2
batch normalization
convolution layer 2
max pooling layer 2: 2x2
batch normalization
convolution layer 3
max pooling layer 3: 8x8
batch normalization
fully connected layer 1
batch normalization
relu
dropout
fully connected layer 2
```

Each of the convolution layers in the network uses the structure in the figure. The scale-steered kernels are the linear combination of the scale-steerable basis. Then they scale the scale-steered kernels to different sizes to convolve with the input and output the max-pooling responses over scales.

Test Error (%)

#### Result

We use the training size of 1k and trained for 300 epochs. The result 4.11±0.13 is a little far from the result in paper 1.91±0.04. As the Colab can run continuously at most 12 hours one time, the training size of 10k would cost more than 20 hours. If we are offered better GPU, we will try to run the experiment for training size of 10k.

| Train/Test Split | Standard CNN    | SS-CNN          | Antialiased-SS-CNN |
| ---------------- | --------------- | --------------- | ------------------ |
| 1                | 7.59            | 4.31            | 4.30               |
| 2                | 7.32            | 4.13            | 4.36               |
| 3                | 7.01            | 3.90            | 4.59               |
| 4                | 8.42            | 4.11            | 4.78               |
| 5                | 7.79            | 4.20            | 5.31               |
| 6                | 7.73            | 3.99            | 5.35               |
| Range            | 7.64 $\pm$ 0.44 | 4.11 $\pm$ 0.13 | 4.78 $\pm$ 0.42    |

